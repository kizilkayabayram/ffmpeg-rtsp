extern "C" {
#include <libavcodec/avcodec.h>
#include <libavutil/imgutils.h>
#include <libavutil/opt.h>
#include <libswscale/swscale.h>
}

#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/core.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/highgui.hpp>
#include <fstream>

void write_to_file(uint8_t *ptr, size_t len) {
  std::ofstream fp;
  fp.open("somefile.png",std::ios::out | std::ios :: binary );
  fp.write((char*)ptr, len);
}


void YUVFrameToRGBData(const AVFrame &frame, uint8_t *data, int bytesPerPixel){
    auto swsContext = sws_getContext(
        frame.width, frame.height,
        AV_PIX_FMT_YUV420P,
        frame.width, frame.height, // same size, just pix fmt changes
        AV_PIX_FMT_RGB24,
        SWS_FAST_BILINEAR, nullptr, nullptr, nullptr);

  uint8_t *outData[1] = {data};
  int outLineSize[1] = {bytesPerPixel*frame.width};
  sws_scale(swsContext, frame.data, frame.linesize, 0, frame.height, outData, outLineSize);
  cv::Mat f(frame.height,frame.width,CV_8UC3,data);
  imwrite("im.jpg",f);
}

int main() {
  auto codec = avcodec_find_encoder(AV_CODEC_ID_H265);
  if (!codec) {
    std::cerr << "Codec with specified id not found" << std::endl;
    return -1;
  }
  auto context = avcodec_alloc_context3(codec);
  if (!context) {
    std::cerr << "Can't allocate video codec context" << std::endl;
    return -1;
  }

  int height = 376;
  int width = 1344;
  int fps = 15;

  /// Resolution must be a multiple of two
  context->height = height;
  context->width = width;


  /// Frames per second
  context->time_base.num = 1;
  context->time_base.den = fps;
  context->framerate.num = fps;
  context->framerate.den = 1;

  /// Only YUV420P for H264|5
  context->pix_fmt = AV_PIX_FMT_YUV420P;

  /// Key(intra) frame rate
  /// looks like option not works for H265 :(
  context->gop_size = fps * 2;

  /// P-frames, generated by referencing data from prev and future frames.
  /// [Compression up, CPU usage up]
  /// [use 3/gop]
  context->max_b_frames = 0;

  /// Can be used by a P-frame(predictive, partial frame) to help define a
  /// future frame in a compressed video. [use 3â€“5 ref per P]
  context->refs = 3;

  /// Compression efficiency (slower -> better quality + higher cpu%)
  /// [ultrafast, superfast, veryfast, faster, fast, medium, slow, slower,
  /// veryslow] Set this option to "ultrafast" is critical for realtime encoding
  av_opt_set(context->priv_data, "preset", "ultrafast", 0);

  /// Compression rate (lower -> higher compression) compress to lower size,
  /// makes decoded image more noisy Range: [0; 51], sane range: [18; 26]. I
  /// used 35 as good compression/quality compromise. This option also critical
  /// for realtime encoding
  av_opt_set(context->priv_data, "crf", "35", 0);

  /// Change settings based upon the specifics of input
  /// [psnr, ssim, grain, zerolatency, fastdecode, animation]
  /// This option is most critical for realtime encoding, because it removes
  /// delay between 1th input frame and 1th output packet.
  av_opt_set(context->priv_data, "tune", "zerolatency", 0);

  auto desc = av_pix_fmt_desc_get(AV_PIX_FMT_RGB24);
  if (!desc) {
    std::cerr << "Can't get descriptor for pixel format" << std::endl;
    return -1;
  }
  auto bytesPerPixel = av_get_bits_per_pixel(desc) / 8;
  if (!(bytesPerPixel == 3 && !(av_get_bits_per_pixel(desc) % 8))) {
    std::cerr << "Unhandled bits per pixel, bad in pix fmt" << std::endl;
    return -1;
  }

  if (avcodec_open2(context, codec, nullptr) < 0) {
    std::cerr << "Could not open codec" << std::endl;
    return -1;
  }

  auto swsContext =
      sws_getContext(width, height, AV_PIX_FMT_RGB24, width, height,
                     AV_PIX_FMT_YUV420P, 0, nullptr, nullptr, nullptr);

  if (!swsContext) {
    std::cerr << "Could not allocate sws context" << std::endl;
    return -1;
  }

  AVPacket packet;
  //av_init_packet(&packet);

  AVFrame *frame;
  frame = av_frame_alloc();
  if (!frame) {
    std::cerr << "Could not allocate video frame" << std::endl;
    return -1;
  }

  frame->format = context->pix_fmt;
  frame->height = context->height;
  frame->width = context->width;

  if (av_frame_get_buffer(frame, 0) < 0) {
    std::cerr << "Can't allocate the video frame data" << std::endl;
    return -1;
  }

  /// I don't know exact reason for fflush, they just do it in official encoding
  /// DOCs
  fflush(stdout);

  /// Making sure the frame data is writable
  if (av_frame_make_writable(frame) < 0) {
    std::cerr << "Frame data not writable" << std::endl;
    return -1;
  }

  cv::VideoCapture camera(0); // in linux check $ ls /dev/video0
  if (!camera.isOpened()) {
    std::cerr << "ERROR: Could not open camera" << std::endl;
  }

  cv::Mat cvframe;

  /// AV_PIX_FMT_RGB24 => AV_PIX_FMT_YUV420P, fill frame data. SWS input data is
  /// just uint8_t* [0; 255] flattened image pixels. Like cv2::Mat.data.

  int frameIdx = 0;

  while (1) {
    camera >> cvframe;
    std::cout<<"channels: "<<cvframe.channels()<<" depth: "<<cvframe.depth()<<" type: "<<cvframe.type()<<std::endl;
    uint8_t *data = cvframe.data;
    const uint8_t *inData[1] = {data};
    int inLineSize[1] = {bytesPerPixel * context->width};
    sws_scale(swsContext, inData, inLineSize, 0, context->height, frame->data,
              frame->linesize);

    /// Set frame index in range: [1, fps]
    frame->pts = frameIdx;

    /// Set frame type
    bool isKeyFrame = false;
    if (isKeyFrame) {
      frame->key_frame = 1;
      frame->pict_type = AVPictureType::AV_PICTURE_TYPE_I;
    }

    std::cout << "Encoding" << std::endl;
    switch (avcodec_send_frame(context, frame)) {
      case 0:
        frameIdx = (frameIdx % context->framerate.num) + 1;
        break;
      case AVERROR(EAGAIN):std::cout << "avcodec_send_frame EAGAIN" << std::endl;
        break;
      case AVERROR_EOF:std::cout << "avcodec_send_frame EOF" << std::endl;
        break;
      case AVERROR(EINVAL):std::cout << " avcodec_send_frame EINVAL" << std::endl;
        break;
      case AVERROR(ENOMEM):std::cout << "avcodec_send_frame ENOMEM" << std::endl;
        break;
    }
    if (cv::waitKey(10) == 27)
      break;

    //YUVFrameToRGBData(*frame, data,bytesPerPixel);
    FILE* file = fopen("file.jpeg", "wb");
    if (!file) {
      exit(1);
    }


    std::cout << "Decoding" << std::endl;
    switch (avcodec_receive_packet(context, &packet)) {
      case 0:
        /// use packet, copy/send it's data, or whatever
        fflush(stdout);


        fwrite(packet.data, 1, packet.size, file);
        av_packet_unref(&packet);
        av_frame_unref(frame);
        if (avcodec_receive_packet(context, &packet) != AVERROR(EAGAIN)) {
          std::cout << "EAGAIN" << std::endl;
          break;
        }
        break;
      case AVERROR(EAGAIN):std::cout << "EAGAIN" << std::endl;
        av_packet_unref(&packet);
        break;
      case AVERROR_EOF:std::cout << "EOF" << std::endl;
        break;
      case AVERROR(EINVAL):std::cout << "EINVAL" << std::endl;
        break;
    }
//    break;
  }

  std::cout << "Interrupted" << std::endl;

  avcodec_free_context(&context);
  sws_freeContext(swsContext);
  av_frame_free(&frame);
}